---
title: "Visualisierung"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Visualisierung}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup}
library(TimeSeries)
library(tidyverse)
library(ggplot2)
library(itsmr)
```
Im Folgenden geben wir einige Beispiele und Anwendungen der Funktionen des Pakets *Time Series*. Im ersten Teil werden wir dazu eine Simulationsstudie durchführen und im zweiten Teil auf reale Daten analysieren:

**1. Simulationsstudie**
  + Autokovarianz-Funktion
  + Durbin-Levinson Algorithmus
  + Innovation Prediction

**2. Analyse realer Daten**

 
 
# Simulationsstudie
In dieser kurzen Simulationsstudio werden die Fähigkeiten des Paketes durch kleine Veränderungen der Parameter veranschaulicht. 

## Autokovarianz-Funktion

In diesem Teil soll die Funktion *acf* getestet werden. Dazu wird ein AR(1)-Prozess mithilfe der Funktion *arma_sim* simuliert. Für diesen Prozess ist es leicht möglich die "wahre" theoretische Autokovarianz-Funktion zu berechnen.

### Theoretische ACF eines AR(1)-Prozesses

Wir nehmen an, dass die Zeitreihe der folgenden Vorraussetztung genügt, wobei $\epsilon$ "white noise" ist:

$$
X_t=\phi X_{t-1}+\epsilon_t
$$
Für die Varianz $\gamma_0$ können wir folgende Berechnungen anstellen:

$$
\gamma(0)=Cov(X_t,X_t)=Cov(\phi X_{t-1}+\epsilon,\phi X_{t-1} + \epsilon_t)=\phi^2 \gamma(0) +\sigma^2= \frac{\sigma^2}{1-\phi^2}
$$
Nun sind auch die weiteren Autokovarianzen leicht bestimmbar:

$$
\gamma(h)=Cov(X_{t},X_{t-h})=Cov(\phi X_{t-1},X_{t-h})+Cov(\epsilon_t,X_{t-h})=\phi\gamma(h-1)+0=... = \phi^h \gamma(0)
$$
Es gilt also:
$$
\gamma(1)=Cov(X_{t},X_{t-1})=...=\phi \gamma_0
$$
$$
\gamma(2)=Cov(X_{t},X_{t-2})=...=\phi^2 \gamma_0
$$
$$
.\\
.\\
.
$$
(Brockwell et.al. (2002), S. 17f).
Wir berechnen nun die theoretischen, ersten 50 Autokovarianzen für den AR(1)-Prozess mit $\phi=0.9$. Wir verwenden eine Standardnormalverteilung für das Rauschen, daher gilt $\sigma_{\epsilon}^2=1$.

```{r, fig.width = 7, fig.asp = .5}
gamma_0 <- 1/(1-0.9^2)
true_acf <- numeric(50)
for(i in 0:49){
        gamma_i <- gamma_0*0.9^i
        true_acf[i+1] <- gamma_i
}
true_tbl <- tibble(ACF=true_acf, Lag=seq_along(true_acf))
true_acf_plot <- ggplot(true_tbl, aes(x=Lag, y=ACF)) +
                geom_bar(stat="identity") + 
                ggtitle("Theoretische ACF: AR(1)")
true_acf_plot
```

Es ist die typische langsam abflachende Autokovarianzfunktion eines AR(1) zu erkennen.

### Vergleich von theoretischer mit geschätzter ACF

Wir simulieren nun Daten mit oben beschriebenen Eigenschaften und schätzen die ACF-Werte ab. Wir wollen testen, wie sich die Zeitreihe mit unterschiedlichen Längen verhält. Dabei wollen wir untersuchen ab welcher Stichprobengröße sich der geschätze ACF-Wert dem theoretischen ACF annähert und betrachten dabei jeweils die ersten 50 Werte. Wir erstellen dafür eine Funktion, welche die simulierten ACFs zusammen mit den theoretischen plottet. 

```{r , fig.width = 7, fig.asp = .5}
set.seed(13)
ar_50 <- arma_sim(phi=0.9,I=50, sd =1)
ar_100 <- arma_sim(phi=0.9,I=100, sd = 1)
ar_500 <- arma_sim(phi=0.9,I=500, sd =1)
ar_2000 <- arma_sim(phi=0.9,I=2000, sd =1)
ar_5000 <- arma_sim(phi=0.9,I=5000, sd =1)

acf_plot <- function(objekt, ...){
        sim_tbl <- tibble(ACF=ACF(objekt)[1:50],Lag=1:50)
        sim_tbl$Group <- "Simulation"
        
        true_tbl <- tibble(ACF=true_acf,Lag=1:50)
        true_tbl$Group <- "Theoretisch"
        
        tbl <- rbind(sim_tbl, true_tbl)
        
        acf_plot <- ggplot(tbl, aes(x=factor(Lag), y=ACF, fill=Group)) +
                geom_bar(stat='identity', position='dodge') + 
                ggtitle(...) +
                scale_x_discrete(name="Lag", breaks=seq(0,50,5))
acf_plot
}
acf_plot(ar_50, "Länge 50") 
acf_plot(ar_100, "Länge 100")
acf_plot(ar_500, "Länge 500")
acf_plot(ar_2000, "Länge 2000")
acf_plot(ar_5000, "Länge 5000")
```
Als zusätzliche Veranschaulichung zeigt der folgende Plot den Zusammenhang zwischen der Länge der Zeitreihe und der Differenz zwischen den theoretischen und simulierten Werten an.

```{r , fig.width = 7, fig.asp = .5}
set.seed(13)
acf_diff_plot <- function(n){
        res <- tibble(Länge=n,Differenz=numeric(n))
        zähler <- 1
        for(i in 1:n){
          a <- ACF(arma_sim(phi=0.9,I=i*50, sd =1))
          diff <- sum(abs(a[1:50]-true_acf))
          res$Länge[zähler] <- i*50
          res$Differenz[zähler] <- diff
          zähler <- zähler+1
        }

        acf_plot <- ggplot(res,aes(x=Länge,y=Differenz)) +
          geom_bar(stat='identity', position='dodge') +
          ggtitle("Differenz der simulierten und theoretischen Daten")
          
        acf_plot
}
######################unebdingt reinmachen nur in Klammer wegen langer berechnungszeit!!!!!!!
#acf_diff_plot(100)
```


Der obige Vergleich zeigt deutlich, dass sich die geschätzte ACF der theoretischen ACF des AR(1)-Prozesses bei größerer Länge annähert. Die Übereinstiummung nimmt bis zu einer Länge der AR(1)-Reihe von 1000 sichtbar zu. Ab diesem Zeitpunkt oszilliert die Differenz auf erstaunlicherweise relativ hohem Niveau. Wir nehmen an, dass diese Oszillation durch den zugrundeliegenden Zufallsprozess erzeugt wird.  

## Durbin-Levinson Algorithmus

In diesem Abschnitt befassen wir uns etwas näher mit dem Durbin-Levinson Algorithmus und wollen uns seiner Vorhersagen bezüglich der ARMA-Zeitreihen anschauen und auch, welchen Einfluss die Parameter $\phi$ und $\theta$ haben und für welche Zeitreihen der Durbin-Levinson Algorithmus aussagekräftig ist. Hierfür erstellen wir eine Prediciton-Funktion, welche uns für die vorherigen $n$ Werte den $n+1$ Wert vorhersagt:

```{r}
DL_Helper <- function(X){

  prediction <- rep(NA, length(X))

  for(i in 10:(length(X))){
    x_help <- X[1:i]
    dl_save <- DLA(x_help)
    prediction[i] <- sum(dl_save*rev(x_help))
  }
  prediction
}
```

Nun simulieren wir Daten mit verschiedenen Eigenschaften und beobachten, welche Auswirkungen die $\phi$ und $\theta$ bei gleichbleibender Stichprobengröße haben und für welche Zeitreihen der DLA akkurat ist.
Hierfür betrachten wir uns sowohl AR(1) und AR(2), als auch MA(1), MA(2) und ARMA(1)-Zeitreihen:

```{r}
set.seed(42)

AR_1 <- arma_sim(phi = 0.6, sd = 0.1, I = 100)
AR_2 <- arma_sim(phi = c(0.5, 0.2), sd = 0.1, I = 100)
MA_1 <- arma_sim(theta = 0.4, sd = 0.1, I = 100)
MA_2 <- arma_sim(theta = c(0.65, 0.25), sd = 0.1, I = 100)
ARMA_1 <- arma_sim(phi = 0.6, theta = 0.4, sd = 0.1, I = 100)

```

Im folgenden berechnen wir nun die Vorhersagen der gegebenen ARMA-Zeitreihen, anhand des DL Algorithmus:

```{r}
DL1 <- DL_Helper(AR_1)
DL2 <- DL_Helper(AR_2)
DL3 <- DL_Helper(MA_1)
DL4 <- DL_Helper(MA_2)
DL5 <- DL_Helper(ARMA_1)
```

Um nun die Genauigkeit des Durbin-Levinson Algorithmus zu überprüfen, plotten wir die ursprüngliche Zeitreihe und die Vorhersage durch den Durbin-Levinson Algorithmus zu vergleichen.

```{r, fig.width = 7, fig.asp = .5}

plot_mult <- function(series, forecast1, forecast2 = NA_real_,  title = "Zeitreihe"){
  tbl <- tibble(Series=series, forecast1 = forecast1, forecast2 = forecast2, Lag=1:100)
  
    ggplot(tbl, aes(x=Lag)) +
    geom_line(aes(y = Series, color = "Series"), size = 0.5, na.rm = T) +
    geom_line(aes(y = forecast1, color = "forecast1"), size = 0.5, na.rm = T) +
    geom_line(aes(y = forecast2, color = "forecast2")) +
    ggtitle(title)
}
```


```{r, fig.width = 7, fig.asp = .5}
plot_mult(series = AR_1, forecast1 =  DL1,  title = "AR(1)")
plot_mult(series = AR_2, forecast1 = DL2, title = "AR(2)")
plot_mult(series = MA_1, forecast1 = DL3, title = "MA(1)")
plot_mult(series = MA_2, forecast1 = DL4, title = "MA(2)")
plot_mult(series = ARMA_1, forecast1 = DL5, title = "ARMA(1)")
```

Wie man erkennen kann, kann der Durbin-Levinson Algorithmus bereits mit wenigen Inputs sehr gute Vorhersagen treffen, die man insbesondere am AR(1) und ARMA(1) erkennt, was in der Theorie auch übereinstimmt. Bei unserem Beispiel sollte der Innovation Algorithmus besser für die MA-Prozesse geeignet sein, wobei man an den Plots auch erkennt, dass der Durbin-Lveinson Algorithmus gute Vorhersagen trifft. Außerdem verringert sich die Ungenauigkeit des Algorithmus je mehr Input dieser bekommt, was schön zu erkennen ist, da bereits bei 60+ die Vorhersage fast exakt mit der Zeitreihe übereinstimmt.

Jetzt wollen wir noch überprüfen, wie gut der Algorithmus damit klarkommt, wenn er mit seinen Vorhersagen weiterrechnet. 

```{r}
DL_Helper_Flaw <- function(X){

  prediction <- rep(NA, length(X))

  for(i in 10:(length(X))){
    x_help <- X[1:i]
    dl_save <- DLA(x_help)
    prediction[i] <- sum(dl_save*rev(x_help))
    X[i] <- prediction[i]
  }
  prediction
}

DL_Flaw1 <- DL_Helper_Flaw(AR_1)
DL_Flaw2 <- DL_Helper_Flaw(MA_1)
DL_Flaw3 <- DL_Helper_Flaw(ARMA_1)
```

```{r, fig.width = 7, fig.asp = .5}
plot_DL(AR_1, DL_Flaw1, "Test")
plot_DL(MA_1, DL_Flaw2, "Test")
plot_DL(ARMA_1, DL_Flaw3, "Test")
```

Auch hier schneidet der Durbin-Levinson solide ab, obwohl man beim MA(1) erkennt, dass dieser vor Allem bei den Peaks deutlich ungenauer ist, als bei den anderen beiden Prozessen, was auch mit unserer Theorie aus dem Brockwell übereinstimmt.
Die Vorhersage ist insbesondere immer flacher und nicht so Spitz wie in unserer tatsächlichen Zeitreihe, was unter anderem damit zusammenhängen kann !!!noch weiterschreiben !!!


## Innovation
Wir betrachten zunächst die letzten Zeilen und ersten Spalten der Innovationmatrix für den AR(1) und den MA(2) - Prozess.
```{r}
M = innovation(AR_1, lag = 99)[90:99,1:6]
rownames(M) = 90:99; M
```

```{r}
M = innovation(MA_2, lag = 99)[90:99,1:6]
rownames(M) = 90:99; M

```
Beim $MA(2)$-Prozess entsprechen die ersten beiden Spalten ungefähr den spezifizierten $MA$-Parametern der Zeitreihe. Der Algorithmus sollte also besonders für die Vorhersage von MA-Prozessen gut geeignet sein.

## Innovation Prediction

Dieser Abschnitt veranschaulicht die Vorhersagegenauigkeit des Innovation Algorithmus. Um einen Vergleich mit dem Durbin-Levinson Algortihmus zu gewährleisten, nutzen wir die analoge Methodik, sowie die selben Zeitreihen, wie oben:

Hierfür erstellen wir eine Prediciton-Funktion, welche uns für die vorherigen $n$ Werte den $n+1$ Wert vorhersagt:

```{r}
innovation_prediction <- function(X){
   inno_prediction <- rep(NA, length(X))

   for(i in 10:(length(X)-1)){
     inno_help <- X[1:i]
     inno_prediction[i+1] <- ts_predict(inno_help,1)
   }
   inno_prediction
}
```

```{r}
innovation_sim_AR_1 <- innovation_prediction(AR_1)
innovation_sim_AR_2 <- innovation_prediction(AR_2)
innovation_sim_MA_1 <- innovation_prediction(MA_1)
innovation_sim_MA_2 <- innovation_prediction(MA_2)
innovation_sim_ARMA_1 <- innovation_prediction(ARMA_1)

```

```{r, fig.width = 7, fig.asp = .5}
plot_mult(AR_1, innovation_sim_AR_1, "AR(1)")
plot_mult(AR_2, innovation_sim_AR_2, "AR(2)")
plot_mult(MA_1, innovation_sim_MA_1, "MA(1)")
plot_mult(MA_2, innovation_sim_MA_2, "MA(2)")
plot_mult(ARMA_1, innovation_sim_ARMA_1, "ARMA(1,1)")
```
Man erkennt hier, dass die Ein-Schritt Prognose den Bewegungen der Zeitreihe folgt, die Ausschläge jedoch nicht so stark sind. Dies liegt daran, dass zur Prognose ein gewichtetes Mittel der Vergangenen Differenzen $\mathbf{X_n} - \mathbf{\hat X_n}$ herangezogen wird, was dazu führt, dass die Prognose tendenziell immer zum Mittelwert strebt. Dieses Verhalten, Bewegungen zu antizipieren, aber zu dämpfen sieht man auch an folgendem Beispiel eines vollständig deterministischen periodischen Prozesses:

```{r}
X = sin(1:65)
forc = ts_predict(X, steps = 30)
```

```{r, fig.width = 7, fig.asp = .5}

```



Nun wollen wir unseren Innovation Vorhersage mit der bestehenden Funktion "forecast" aus dem Paket "itsmr" (https://mparison <- georgeweigt.github.io/itsmr-refman.pdf, Seite 14) vergleichen:

```{r}

itsmr_prediction_1 <- forecast(AR_2, #Time series data
                             M = NULL, #Data model
                             a = arma(AR_2, p=10, q=0), #ARMA model
                             h = 10, #Steps ahead
                             opt = 0, #Display option (0 silent, 1 tabulate, 2 plot and tabulate)
                             alpha = 1)$pred #Level of significance
innovation_sim_1 <- ts_predict(AR_2, 10)
itsmr_prediction_2 <- forecast(MA_2, #Time series data
                             M = NULL, #Data model
                             a = arma(MA_2, p=0, q=10), #ARMA model
                             h = 10, #Steps ahead
                             opt = 0, #Display option (0 silent, 1 tabulate, 2 plot and tabulate)
                             alpha = 1)$pred #Level of significance
innovation_sim_2 <- ts_predict(MA_2, 10)

# itsmr_prediction <- function(X){
#    inno_prediction <- rep(NA, length(X))
# 
#    for(i in 10:(length(X)-1)){
#      inno_help <- X[1:i]
#      inno_prediction[i+1] <- forecast(inno_help,
#                                       M =NULL,
#                                       a = arma(inno_help, p = 10, q = 0),
#                                       h = 1,
#                                       opt = 0)
#      }
#    inno_prediction
# }
```

```{r , fig.width = 7, fig.asp = .5}



plot_timeseries(AR_2, itsmr_prediction_1, "AR_2 mit forecast")
plot_timeseries(AR_2, innovation_sim_1, "AR_2 mit ts_predict" )
plot_timeseries(MA_2, itsmr_prediction_2, "MA_2 mit forecast")
plot_timeseries(MA_2, innovation_sim_2, "MA_2 mit ts_predict")
```

Wir können zunächst festhalten, dass die "forecast"-Funktion dem Nutzer mehr Parameter zur Verfügung stellt. Mit einer geeigneten Wahl von q und p, welche allerdings vom hier vorliegenden Prozess abweicht, 



##Reale Daten

```{r}
data <- as_tibble(read.delim("Luftdaten_stunde_19480101_20201231_05906.txt",
                             header = T,
                             sep = ";",
                             dec = "."))

data %>% 
  select(time = MESS_DATUM, temp = TT_TU) %>%
  filter((abs(temp) < 50) & (2000010100 <= time) ) -> data_hourly

data_hourly %>% 
  separate(time, sep = 6, into = "date") %>% 
  group_by(date) %>% 
  summarise(temp = mean(temp)) -> data_mon

data_hourly
data_mon

plot(data_mon, type  = "l")


#periodo <- perio(data_daily$temp)

#plot_periodogram(periodo, logscale = T)
#periodo
```

Als nächstes betrachten wir einen kleinen Ausschnitt der Daten und versuchen anhand von 100 Datenwerten die einem gewissen Muster folgen eine Vorhersage zu treffen:
```{r, fig.width = 7, fig.asp = .5}
plot_predic <- function(series, dl, ...){
  len <- length(series)
  dl[1:100] <- rep(NA,100)
  tbl <- tibble(Series=series, DL_obj = dl, Lag=1:len)
  
   ggplot(tbl, aes(x=Lag)) + 
    geom_line(aes(y = Series), color = "blue", size=0.4,na.rm=T) + 
    geom_line(aes(y = DL_obj), color= "red", size=0.4,na.rm=T) +
    ggtitle(...)
}

raw <- data_hourly$temp[3700:3800]-mean(data_hourly$temp[3700:3800])
raw_full <- data_hourly$temp[3700:3830]-mean(data_hourly$temp[3700:3830])
predic_DL <- DL_prediction(raw,len=30,all=T)
predic_IN <- ts_predict(raw,steps=30,all=T)

plot_predic(raw_full, predic_DL,"Vorhersage Durbin-Levinson")
plot_predic(raw_full, predic_IN,"Vorhersage Innovation")

acf_plot <- ggplot(tibble(ACF=ACF(raw), Lag=seq_along(ACF(raw))), aes(x=Lag, y=ACF)) +
                geom_bar(stat="identity") + 
                ggtitle("ACF-Plot")
acf_plot
```
Wir sehen, dass die Vorhersage durch den *DL_predict* einen sehr starken Ausschlag als ersten Wert hat und auch danach die Zeitreihe nicht so gut vorhersagen kann wie die *ts_predict*-Funktion. Dies legt die Vermutung nahe, dass es sich hier ehr um einen MA-Prozess handel. Dies bestätigt auch der entsprechende ACF-Plot, hier sieht ein schnelles Abfallen der Bar-Plots, was typtisch für einen MA-Prozess ist. Wie bereits oben erklärt können erneut die Maxima nicht sehr gut aufgelöst werden. Es lohnt sich also den entsprechenden ACF-Plot anzuschauen um zu entscheiden welche Prediction-Funktion die Daten besser modellieren kann.  


